{{- if .Values.ollama.enabled }}
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "airbud.fullname" . }}-ollama
  labels:
    {{- include "airbud.labels" . | nindent 4 }}
    component: ollama
spec:
  replicas: {{ .Values.ollama.replicaCount }}
  selector:
    matchLabels:
      {{- include "airbud.selectorLabels" . | nindent 6 }}
      component: ollama
  template:
    metadata:
      labels:
        {{- include "airbud.selectorLabels" . | nindent 8 }}
        component: ollama
    spec:
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      containers:
        - name: ollama
          image: "{{ .Values.ollama.image.repository }}:{{ .Values.ollama.image.tag }}"
          imagePullPolicy: {{ .Values.ollama.image.pullPolicy }}
          ports:
            - name: http
              containerPort: 11434
              protocol: TCP
          env:
            - name: OLLAMA_HOST
              value: "0.0.0.0"
          volumeMounts:
            - name: ollama-storage
              mountPath: /root/.ollama
          resources:
            {{- toYaml .Values.ollama.resources | nindent 12 }}
          livenessProbe:
            tcpSocket:
              port: 11434
            initialDelaySeconds: 60
            periodSeconds: 20
          readinessProbe:
            tcpSocket:
              port: 11434
            initialDelaySeconds: 15
            periodSeconds: 10
        
        # --- SIDE CAR: Model Loader ---
        - name: model-loader
          image: "{{ .Values.ollama.image.repository }}:{{ .Values.ollama.image.tag }}"
          imagePullPolicy: {{ .Values.ollama.image.pullPolicy }}
          command: ["/bin/sh", "-c"]
          args:
            - |
              echo "Waiting for Ollama API..."
              # Wait until we can list models (implies server is up)
              until ollama list > /dev/null 2>&1; do 
                echo "..."
                sleep 5
              done
              
              echo "Ollama is ready! Pulling models..."
              ollama pull granite3.2-vision
              
              echo "model pulled. Sleeping..."
              sleep infinity
          env:
            - name: OLLAMA_HOST
              value: "localhost:11434"
          resources:
            requests:
              cpu: "100m"
              memory: "128Mi"
            limits:
              cpu: "500m"
              memory: "512Mi"
      
      volumes:
        - name: ollama-storage
        {{- if .Values.ollama.persistence.enabled }}
          persistentVolumeClaim:
            claimName: {{ include "airbud.fullname" . }}-ollama-data
        {{- else }}
          emptyDir: {}
        {{- end }}
      
      # --- GPU CONFIG ---
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.affinityGPU }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerationsGPU }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
{{- end }}
