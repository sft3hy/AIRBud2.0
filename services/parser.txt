== FILE / FOLDER STRUCTURE (relative to /Users/samueltownsend/dev/cosmic/Advanced-Rag-Microservices/services/parser) ==
./
src/
src/core/
src/utils/
Dockerfile
main.py
requirements.txt
src/core/document_parser.py
src/utils/chart_detection.py


== CONCATENATED FILE CONTENTS ==

---- FILE: Dockerfile ----
# Use a specific stable version (Bookworm) to avoid unstable repo mirrors
FROM python:3.10-slim-bookworm

# Install system dependencies
# Added --fix-missing to handle connection drops during large downloads
RUN apt-get update && apt-get install -y --fix-missing \
    git \
    libgl1 \
    libglib2.0-0 \
    poppler-utils \
    tesseract-ocr \
    g++ \
    gcc \
    libreoffice \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# 1. Install PyTorch CPU first (works for Mac & Prod Parser)
RUN pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu

# 2. Install Detectron2
RUN python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8001"]

---- FILE: main.py ----
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import os
from src.core.document_parser import DocumentParser

app = FastAPI()


class ParseRequest(BaseModel):
    file_path: str
    output_dir: str


@app.post("/parse")
def parse_document(req: ParseRequest):
    print(f"Received parse request for: {req.file_path}")

    if not os.path.exists(req.file_path):
        raise HTTPException(status_code=404, detail="File not found")

    os.makedirs(req.output_dir, exist_ok=True)

    # Initialize parser (Vision is None because this service only detects/crops)
    parser = DocumentParser(vision_model=None, output_dir=req.output_dir)

    try:
        # Helper to get both text and images
        markdown_text, image_paths = parser.parse_and_get_images(req.file_path)
        return {"text": markdown_text, "images": image_paths}
    except Exception as e:
        print(f"Error parsing: {e}")
        raise HTTPException(status_code=500, detail=str(e))


---- FILE: requirements.txt ----
fastapi
uvicorn
python-multipart
opencv-python-headless
numpy
pillow
pdf2image
python-docx
python-pptx
pymupdf
requests

---- FILE: src/core/document_parser.py ----
import os
import re
import io
import fitz  # PyMuPDF
from PIL import Image
from docx import Document
from pptx import Presentation
from typing import List, Tuple, Dict, Optional
import subprocess
import tempfile

# Import Chart Detector
from src.utils.chart_detection import PubLayNetDetector


class DocumentParser:
    def __init__(self, vision_model, output_dir: str):
        self.output_dir = output_dir
        self.layout_detector = PubLayNetDetector(confidence_threshold=0.5, padding=60)

    def parse_and_get_images(self, file_path: str) -> Tuple[str, List[str]]:
        """
        Parses document, extracts text, detects charts, saves crops.
        Returns: (markdown_text, list_of_saved_image_paths)
        """
        file_ext = os.path.splitext(file_path)[1].lower()
        file_output_dir = os.path.join(
            self.output_dir, os.path.splitext(os.path.basename(file_path))[0]
        )
        os.makedirs(file_output_dir, exist_ok=True)

        extracted_images = []

        if file_ext == ".pdf":
            text = self._extract_from_pdf(file_path, file_output_dir, extracted_images)
        elif file_ext == ".docx":
            text = self._extract_from_docx(file_path, file_output_dir, extracted_images)
        elif file_ext == ".pptx":
            text = self._extract_from_pptx(file_path, file_output_dir, extracted_images)
        else:
            raise ValueError(f"Unsupported format: {file_ext}")

        return text, extracted_images

    def _extract_from_pdf(self, path, output_dir, img_list):
        doc = fitz.open(path)
        full_text = []
        for i, page in enumerate(doc):
            # Text
            full_text.append(f"## Page {i+1}\n{page.get_text()}")

            # Image for detection
            pix = page.get_pixmap(matrix=fitz.Matrix(2.0, 2.0))
            img = Image.open(io.BytesIO(pix.tobytes("png")))

            # Detect & Crop
            crops = self._process_visuals(img, f"page{i+1}", output_dir)
            img_list.extend(crops)

            # Add placeholders
            for crop_path in crops:
                filename = os.path.basename(crop_path)
                full_text.append(f"\n[CHART_PLACEHOLDER:{filename}]\n")

        return "\n".join(full_text)

    def _extract_from_docx(self, path, output_dir, img_list):
        doc = Document(path)
        full_text = []
        for para in doc.paragraphs:
            full_text.append(para.text)

        # Extract images from relationships
        for rel in doc.part.rels.values():
            if "image" in rel.target_ref:
                try:
                    img_data = rel.target_part.blob
                    img = Image.open(io.BytesIO(img_data))
                    if img.width > 150 and img.height > 150:
                        fname = f"docx_img_{len(img_list)}.png"
                        save_path = os.path.join(output_dir, fname)
                        img.save(save_path)
                        img_list.append(save_path)
                        full_text.append(f"\n[CHART_PLACEHOLDER:{fname}]\n")
                except Exception as e:
                    print(f"Error extracting DOCX image: {e}")

        return "\n\n".join(full_text)

    def _extract_from_pptx(self, path, output_dir, img_list):
        print(f"Processing PPTX: {path}")
        prs = Presentation(path)
        full_text = []

        # 1. Convert Slides to Images (requires LibreOffice)
        slide_images = self._convert_pptx_to_images(path)
        print(f"  Converted {len(slide_images)} slides to images.")

        for i, slide in enumerate(prs.slides):
            full_text.append(f"## Slide {i+1}")

            # Text Extraction
            for shape in slide.shapes:
                if hasattr(shape, "text") and shape.text.strip():
                    full_text.append(shape.text)

            # Visual Processing
            if i < len(slide_images):
                # Detect & Crop charts from the rendered slide
                crops = self._process_visuals(
                    slide_images[i], f"slide{i+1}", output_dir
                )
                img_list.extend(crops)

                for crop_path in crops:
                    filename = os.path.basename(crop_path)
                    full_text.append(f"\n[CHART_PLACEHOLDER:{filename}]\n")

        return "\n\n".join(full_text)

    def _convert_pptx_to_images(self, pptx_path) -> List[Image.Image]:
        images = []
        try:
            with tempfile.TemporaryDirectory() as tmpdir:
                # Convert PPTX -> PDF using LibreOffice
                # --headless: no UI
                # --outdir: where to put the pdf
                cmd = [
                    "soffice",
                    "--headless",
                    "--convert-to",
                    "pdf",
                    "--outdir",
                    tmpdir,
                    pptx_path,
                ]

                print("  Running LibreOffice conversion...")
                subprocess.run(
                    cmd,
                    check=True,
                    timeout=120,
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.DEVNULL,
                )

                # The output file has the same name but .pdf extension
                pdf_name = os.path.splitext(os.path.basename(pptx_path))[0] + ".pdf"
                pdf_path = os.path.join(tmpdir, pdf_name)

                if os.path.exists(pdf_path):
                    # Load PDF -> Images using PyMuPDF (fitz)
                    doc = fitz.open(pdf_path)
                    for page in doc:
                        # High resolution for better detection
                        pix = page.get_pixmap(matrix=fitz.Matrix(2.0, 2.0))
                        img = Image.open(io.BytesIO(pix.tobytes("png")))
                        images.append(img)
                    doc.close()
                else:
                    print("  Warning: LibreOffice finished but PDF was not found.")

        except Exception as e:
            print(f"PPTX Image Conversion Failed: {e}")
            print("Ensure 'libreoffice' is installed in the container.")

        return images

    def _process_visuals(self, page_image, prefix, output_dir) -> List[str]:
        bboxes = self.layout_detector.detect(page_image)
        saved_paths = []
        for i, (x1, y1, x2, y2) in enumerate(bboxes):
            crop = page_image.crop((x1, y1, x2, y2))
            fname = f"{prefix}_visual_{i+1}.png"
            path = os.path.join(output_dir, fname)
            crop.save(path)
            saved_paths.append(path)
        return saved_paths


---- FILE: src/utils/chart_detection.py ----
"""
src/utils/chart_detection.py

Chart detection module using Detectron2 with PubLayNet weights.
Includes fallback to Computer Vision heuristics if ML fails or is disabled.
"""

import os
import sys
import shutil
import requests
import tempfile
from pathlib import Path
from typing import List, Tuple, Optional, Dict, Any

# Image processing
from PIL import Image
import cv2
import numpy as np
import torch
import gc

# Detectron2 imports (Guarded)
try:
    from detectron2.config import get_cfg
    from detectron2.engine import DefaultPredictor
    from detectron2 import model_zoo

    _DETECTRON2_AVAILABLE = True
except ImportError:
    _DETECTRON2_AVAILABLE = False


class ChartDetector:
    """Base interface for chart detection."""

    def detect(self, page_image: Image.Image) -> List[Tuple[int, int, int, int]]:
        """
        Detect charts/figures in a page image.
        Returns: List of bounding boxes (x1, y1, x2, y2)
        """
        return []

    def offload_model(self):
        """Free up resources."""
        pass


class PubLayNetDetector(ChartDetector):
    """
    Detects Charts, Tables, and Figures using Faster R-CNN (ResNet50)
    trained on the PubLayNet dataset.
    """

    def __init__(self, confidence_threshold=0.5, padding=75):
        self.confidence_threshold = confidence_threshold
        self.padding = padding
        self.predictor = None
        self.cfg = None
        self._is_loaded = False

        # PubLayNet Label Map (6 classes)
        self.label_map = {
            0: "Text",
            1: "Title",
            2: "List",
            3: "Table",
            4: "Figure",
            5: "Other",
        }

        # Target classes to extract (We usually want Figures and Tables for charts)
        self.target_classes = ["Figure", "Table"]

    def load_model(self):
        """Initialize the Detectron2 model."""
        if self._is_loaded:
            return

        if not _DETECTRON2_AVAILABLE:
            print("Warning: Detectron2 not installed. Falling back to CV heuristics.")
            return

        print("Loading PubLayNet Detector...")
        try:
            # 1. Setup Base Config
            base_config = "COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml"
            self.cfg = get_cfg()
            self.cfg.merge_from_file(model_zoo.get_config_file(base_config))

            # 2. Modify Config
            self.cfg.MODEL.ROI_HEADS.NUM_CLASSES = 6
            self.cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = self.confidence_threshold

            # Device selection
            if torch.cuda.is_available():
                self.cfg.MODEL.DEVICE = "cuda"
            elif torch.backends.mps.is_available():
                self.cfg.MODEL.DEVICE = "cpu"
            else:
                self.cfg.MODEL.DEVICE = "cpu"

            # 3. Ensure Weights
            self._ensure_publaynet_weights()

            # 4. Create Predictor
            self.predictor = DefaultPredictor(self.cfg)
            self._is_loaded = True
            print(f"✓ PubLayNet loaded on {self.cfg.MODEL.DEVICE}")

        except Exception as e:
            print(f"✗ Failed to load PubLayNet model: {e}")
            print("Falling back to CV heuristics.")

    def _ensure_publaynet_weights(self):
        """Download weights if not present."""
        model_url = "https://www.dropbox.com/s/dgy9c10wykk4lq4/model_final.pth?dl=1"
        cache_dir = Path.home() / ".torch" / "detectron2_models"
        cache_dir.mkdir(parents=True, exist_ok=True)
        model_path = cache_dir / "publaynet_faster_rcnn_R_50_FPN_3x.pth"

        if not model_path.exists():
            print(f"Downloading PubLayNet weights (~330MB)...")
            try:
                response = requests.get(model_url, stream=True, allow_redirects=True)
                response.raise_for_status()
                with open(model_path, "wb") as f:
                    for chunk in response.iter_content(chunk_size=1024 * 1024):
                        if chunk:
                            f.write(chunk)
                print("Download complete.")
            except Exception as e:
                if model_path.exists():
                    model_path.unlink()
                raise e

        self.cfg.MODEL.WEIGHTS = str(model_path)

    def detect(self, page_image: Image.Image) -> List[Tuple[int, int, int, int]]:
        """
        Runs detection on a PIL Image.
        Returns list of bboxes: (x1, y1, x2, y2)
        """
        # Ensure model is loaded
        if not self._is_loaded and _DETECTRON2_AVAILABLE:
            self.load_model()

        # Convert PIL to CV2 (BGR)
        img_np = np.array(page_image)
        if img_np.shape[-1] == 4:  # Handle RGBA
            img_np = cv2.cvtColor(img_np, cv2.COLOR_RGBA2BGR)
        else:
            img_np = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)

        detections = []

        # 1. Try ML Detection
        if self._is_loaded and self.predictor:
            try:
                outputs = self.predictor(img_np)
                instances = outputs["instances"].to("cpu")
                boxes = instances.pred_boxes.tensor.numpy()
                scores = instances.scores.numpy()
                classes = instances.pred_classes.numpy()
                img_h, img_w = img_np.shape[:2]

                for box, score, cls_id in zip(boxes, scores, classes):
                    cls_name = self.label_map.get(int(cls_id), "Unknown")

                    if cls_name in self.target_classes:
                        x1, y1, x2, y2 = map(int, box)

                        # Apply Padding
                        x1 = max(0, x1 - self.padding)
                        y1 = max(0, y1 - self.padding)
                        x2 = min(img_w, x2 + self.padding)
                        y2 = min(img_h, y2 + self.padding)

                        detections.append((x1, y1, x2, y2))

                # If ML found something, return it. If not, try fallback?
                # Usually if ML runs but finds nothing, there is nothing.
                # But we can be aggressive and try CV if ML yields 0.
                if detections:
                    return detections

            except Exception as e:
                print(f"Prediction error: {e}")

        # 2. Fallback CV Heuristics
        print("Using CV fallback for chart detection...")
        return self._detect_cv_fallback(img_np)

    def _detect_cv_fallback(self, img: np.ndarray) -> List[Tuple[int, int, int, int]]:
        """Heuristic detection using Canny edges and contours."""
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        img_h, img_w = img.shape[:2]

        # Edge detection + Dilation to merge text blocks
        edges = cv2.Canny(gray, 50, 150)
        dilated = cv2.dilate(edges, np.ones((5, 5), np.uint8), iterations=3)
        contours, _ = cv2.findContours(
            dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )

        bboxes = []
        for cnt in contours:
            x, y, w, h = cv2.boundingRect(cnt)

            # Filter noise
            if w < 100 or h < 100:
                continue
            if w / h > 5 or h / w > 5:
                continue  # Ignore extreme aspect ratios (lines)

            area_pct = (w * h) / (img_w * img_h)
            if area_pct < 0.05 or area_pct > 0.9:
                continue

            # Apply Padding
            x_pad = max(0, x - self.padding)
            y_pad = max(0, y - self.padding)
            w_pad = min(img_w - x_pad, w + 2 * self.padding)
            h_pad = min(img_h - y_pad, h + 2 * self.padding)

            bboxes.append((x_pad, y_pad, x_pad + w_pad, y_pad + h_pad))

        return bboxes

    def offload_model(self):
        """Release resources to free up GPU/RAM."""
        if not self._is_loaded:
            return

        print("Offloading PubLayNet Detector...")
        self.predictor = None
        self.cfg = None
        self._is_loaded = False

        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
        elif torch.backends.mps.is_available():
            torch.mps.empty_cache()

        print("✓ PubLayNet offloaded.")


# Backward compatibility / Helper Factory
def get_detector() -> ChartDetector:
    """Returns the best available detector."""
    return PubLayNetDetector()


# Deprecated classes kept for interface compatibility if needed
class HeuristicDetector(ChartDetector):
    def detect(self, page_image: Image.Image) -> List[Tuple[int, int, int, int]]:
        det = PubLayNetDetector()
        # Force fallback behavior
        det._is_loaded = False
        img_np = np.array(page_image)
        if img_np.shape[-1] == 4:
            img_np = cv2.cvtColor(img_np, cv2.COLOR_RGBA2BGR)
        else:
            img_np = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)
        return det._detect_cv_fallback(img_np)


