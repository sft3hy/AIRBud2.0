FROM nvidia/cuda:13.1.1-cudnn-runtime-ubuntu24.04

# System dependencies for OpenCV and Audio
# Fix for OpenSSL 3.0 / Ubuntu 24.04 SSL errors
RUN apt-get update && apt-get install -y \
    git \
    python3 \
    python3-pip \
    libgl1 \
    libglib2.0-0 \
    ffmpeg \
    ca-certificates \
    && update-ca-certificates \
    && sed -i 's/CipherString = DEFAULT@SECLEVEL=2/CipherString = DEFAULT@SECLEVEL=1/' /etc/ssl/openssl.cnf \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Environment variables for Offline Model Caching
ENV HF_HOME=/app/model_cache/huggingface \
    XDG_CACHE_HOME=/app/model_cache \
    PATH="/usr/local/bin:$PATH"

COPY requirements.txt .
# Install GPU Torch first for efficiency
# Using cu124 index as it's the current stable high-Cuda target for Torch 2.4+
# Trusted-host added to bypass SSL issues on Ubuntu 24.04 in restricted environments
RUN python3 -m pip install --no-cache-dir torch torchvision \
    --index-url https://download.pytorch.org/whl/cu124 \
    --trusted-host download.pytorch.org \
    --break-system-packages

RUN python3 -m pip install --no-cache-dir -r requirements.txt \
    --trusted-host pypi.org \
    --trusted-host files.pythonhosted.org \
    --break-system-packages

# --- OFFLINE PRE-LOAD STEP ---
RUN python3 -c "import whisper; \
    import os; \
    from transformers import AutoModelForCausalLM, AutoTokenizer; \
    AutoTokenizer.from_pretrained('vikhyatk/moondream2', revision='2025-06-21', trust_remote_code=True); \
    AutoModelForCausalLM.from_pretrained('vikhyatk/moondream2', revision='2025-06-21', trust_remote_code=True); \
    print('Downloading Whisper Medium...'); \
    whisper.load_model('medium'); \
    print('Downloading Moondream2...');"


COPY . .

EXPOSE 8002
CMD ["gunicorn", "main:app", "-w", "4", "-k", "uvicorn.workers.UvicornWorker", "-b", "0.0.0.0:8002", "--threads", "2", "--timeout", "120"]
