services:
  init_fs:
    image: alpine:latest
    container_name: smart_rag_init_fs
    # Create directories and force permissions to 777 so all containers (root or appuser) can RWX
    command: sh -c "mkdir -p /data/uploads /data/charts /data/faiss_indexes /data/chunks /data/huggingface /data/previews && chmod -R 777 /data"
    volumes:
      - shared_data:/data

  # --- Gateway ---
  nginx:
    image: nginx:alpine
    container_name: smart_rag_nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/certs:/etc/nginx/certs:ro
      - ./nginx/html:/usr/share/nginx/html:ro
    depends_on:
      - frontend
      - rag_core
      - kg_service
    logging:
      driver: "json-file"
      options:
        max-size: "500m"
        max-file: "3"

  # 1. Frontend
  frontend:
    build:
      context: ./services/frontend
      dockerfile: Dockerfile
    container_name: smart_rag_frontend
    ports:
      - "5173:5173"
    environment:
      - VITE_API_URL=http://localhost:8000
      - VITE_NETWORK=LOW
      - VITE_TEST_MODE=${TEST:-False}
      - WATCHPACK_POLLING=true
      - CHOKIDAR_USEPOLLING=true # Better for Docker file watching
    volumes:
      - ./services/frontend:/app
      - /app/node_modules
    command: sh -c "npm install && npm run dev -- --host" # Run install on startup
    depends_on:
      - rag_core

  # 2. RAG Core
  rag_core:
    build: ./services/rag_core
    container_name: smart_rag_core
    environment:
      - GROQ_API_KEY=${GROQ_API_KEY}
      - SANCTUARY_API_KEY=${SANCTUARY_API_KEY}
      - TEST=False
      - LLM_PROVIDER=groq
      - PARSER_API_URL=http://parser:8001
      - VISION_API_URL=http://vision:8002
      - PYTHONUNBUFFERED=1
      - POSTGRES_SERVER=postgres
      - POSTGRES_USER=rag_user
      - POSTGRES_PASSWORD=rag_password
      - POSTGRES_DB=rag_db
      - HF_HOME=/data/huggingface
    volumes:
      - shared_data:/data
      - ./services/rag_core:/app
    depends_on:
      parser:
        condition: service_started
      vision:
        condition: service_started
      postgres:
        condition: service_healthy
    # --- FIX: Add ( ... || true) to ignore permission errors on existing files ---
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload --proxy-headers
    # ----------------------------------------------------------------------------

  # 3. Parser
  parser:
    build:
      context: ./services/parser
      dockerfile: Dockerfile.test
    container_name: smart_rag_parser
    ports:
      - "8001:8001"
    environment:
      - PYTHONUNBUFFERED=1
    volumes:
      - shared_data:/data
      - ./services/parser:/app
    command: >
      /bin/sh -c "mkdir -p /data/charts &&
      uvicorn main:app --host 0.0.0.0 --port 8001 --reload"

  # 4. Vision
  vision:
    build: ./services/vision
    container_name: smart_rag_vision
    ports:
      - "8002:8002"
    environment:
      - PYTHONUNBUFFERED=1
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
    volumes:
      - shared_data:/data
      - huggingface_cache:/root/.cache/huggingface
      - ./services/vision:/app
    extra_hosts:
      - "host.docker.internal:host-gateway"
    # --- FIX: Add || true ---
    command: /bin/sh -c "mkdir -p /data/charts && (chmod -R 777 /data/charts || true) && uvicorn main:app --host 0.0.0.0 --port 8002 --reload"

  # 5. Postgres
  postgres:
    image: postgres:15-alpine
    container_name: smart_rag_postgres
    restart: always
    environment:
      - POSTGRES_USER=rag_user
      - POSTGRES_PASSWORD=rag_password
      - POSTGRES_DB=rag_db
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U rag_user -d rag_db"]
      interval: 5s
      timeout: 5s
      retries: 5

  # 6. PGAdmin
  pgadmin:
    image: dpage/pgadmin4
    container_name: pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@example.com
      PGADMIN_DEFAULT_PASSWORD: admin
      PGADMIN_CONFIG_CONSOLE_LOG_LEVEL: 50
      PGADMIN_CONFIG_FILE_LOG_LEVEL: 50
    ports:
      - "5050:80"
    depends_on:
      - postgres
    volumes:
      - pgadmin_data:/var/lib/pgadmin
      - /dev/null:/var/log/pgadmin
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # 7. KG Service
  kg_service:
    build: ./services/kg_service
    container_name: smart_rag_kg
    ports:
      - "8003:8003"
    environment:
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=smartrag_password
      - GROQ_API_KEY=${GROQ_API_KEY}
      - SANCTUARY_API_KEY=${SANCTUARY_API_KEY}
      - TEST=False
      - PYTHONUNBUFFERED=1
    volumes:
      - ./services/kg_service:/app
    depends_on:
      neo4j:
        condition: service_healthy
    command: uvicorn main:app --host 0.0.0.0 --port 8003 --reload

  # 8. Neo4j
  neo4j:
    image: neo4j:5.15-community
    container_name: smart_rag_neo4j
    ports:
      - "7474:7474"
      - "7687:7687"
    environment:
      - NEO4J_AUTH=neo4j/smartrag_password
      - NEO4J_dbms_memory_heap_initial__size=512m
      - NEO4J_dbms_memory_heap_max__size=1G
    volumes:
      - neo4j_data:/data
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget --no-verbose --tries=1 --spider localhost:7474 || exit 1",
        ]
      interval: 10s
      timeout: 5s
      retries: 5

  # 9. Monitoring: InfluxDB
  influxdb:
    image: influxdb:2.7
    container_name: smart_rag_influxdb
    ports:
      - "8086:8086"
    volumes:
      - influxdb_data:/var/lib/influxdb2
    environment:
      - DOCKER_INFLUXDB_INIT_MODE=setup
      - DOCKER_INFLUXDB_INIT_USERNAME=admin
      - DOCKER_INFLUXDB_INIT_PASSWORD=smartrag_password
      - DOCKER_INFLUXDB_INIT_ORG=smartrag_org
      - DOCKER_INFLUXDB_INIT_BUCKET=glances
      - DOCKER_INFLUXDB_INIT_ADMIN_TOKEN=smartrag-admin-token
    # --- FIX 1: Add Healthcheck ---
    healthcheck:
      test: "curl -f http://localhost:8086/health || exit 1"
      interval: 5s
      timeout: 10s
      retries: 5
      start_period: 20s

  # 10. Monitoring: Glances
  glances:
    image: nicolargo/glances:latest-full
    container_name: smart_rag_monitor
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./monitoring/glances/glances.conf:/glances/conf/glances.conf:ro # Standard path
    environment:
      - DOCKER_HOST=unix://var/run/docker.sock
      - PYTHONUNBUFFERED=1 # Force logs to appear immediately
    # --- FIX: Explicit Command (Debug mode, specific config, export) ---
    command: /bin/sh -c "glances -C /glances/conf/glances.conf -q --export influxdb2 --debug"
    # -------------------------------------------------------------------
    privileged: true
    pid: host
    depends_on:
      influxdb:
        condition: service_healthy

  # 11. Monitoring: Grafana (The Dashboard)
  grafana:
    image: grafana/grafana:latest
    container_name: smart_rag_grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=smartrag
    volumes:
      - grafana_data:/var/lib/grafana
    depends_on:
      - influxdb

  # 12. Backup service
  backups:
    build: ./services/backup
    container_name: smart_rag_backups
    environment:
      - TZ=America/New_York
      - BACKUP_SCHEDULE=0 0 * * 3 # Wednesday at Midnight
      - POSTGRES_SERVER=postgres
      - POSTGRES_USER=rag_user
      - POSTGRES_PASSWORD=rag_password
      - POSTGRES_DB=rag_db
    volumes:
      # Use /var/run/docker.sock to allow this container to stop/start Neo4j
      - /var/run/docker.sock:/var/run/docker.sock
      # Mount shared volumes to backup
      - shared_data:/shared_data:ro
      - shared_data:/backups # Write backups here (inside /data/backups)
      - neo4j_data:/neo4j_data:ro
      - ./services/rag_core:/source_code:ro
    depends_on:
      - postgres
      - neo4j

volumes:
  pgadmin_data:
  shared_data:
  huggingface_cache:
  postgres_data:
  neo4j_data:
  influxdb_data:
  grafana_data:
